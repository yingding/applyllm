{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dce6ec1-4e23-4d4c-b2b7-6c2de9b465c5",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "@Author: Yingding Wang\\\n",
    "@CreatedOn: 20.11.2023\n",
    "\n",
    "This notebook shows an example of using pdf data from a S3 bucket source to be translated from german lanuage into english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0080c33-175c-40e3-b1e8-ade3814f7f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.29.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "boto3.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d85ef3af-bda8-435c-96cd-55ff0ae716dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list=!nvidia-smi -L\n",
    "#for i in range(len(list)):\n",
    "#    print(list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c714714-0c21-499d-af92-be62f99e83a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a43205b-2859-4597-b5db-358ad085a6a8",
   "metadata": {},
   "source": [
    "## Init the GPU environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d7ac77b-3047-4eb4-b2db-ecb1859c6938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.accelerator_utils import AcceleratorStatus, AcceleratorHelper\n",
    "gpu_status = AcceleratorStatus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a21b910f-f21e-4e68-9d05-1327510f4bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_of_gpus: 1\n",
      "--------------------\n",
      "Device name      : NVIDIA A100 80GB PCIe MIG 2g.20gb \n",
      "Device idx       : 0 \n",
      "No. of processors: 28\n",
      "Physical  memory : 19.500000 GB\n",
      "Reserved  memory : 0.000000 GB\n",
      "Allocated memory : 0.000000 GB\n",
      "Free      memory : 0.000000 GB\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "gpu_status.gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a703cf63-bee5-4f29-aa28-8f11e461ae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_helper = AcceleratorHelper()\n",
    "UUIDs = gpu_helper.nvidia_device_uuids_filtered_by(is_mig=True, log_output=False)\n",
    "# print(UUIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc8923a3-d0e5-494e-86de-a0eeb0de80e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIG-0efc9f06-6dca-5886-98af-0273ca7fde51\n",
      "/home/jovyan/llm-models/core-kind/yinwang/models\n"
     ]
    }
   ],
   "source": [
    "# set the model download cache directory\n",
    "display_architecture=True\n",
    "DATA_ROOT=\"/home/jovyan/llm-models\"\n",
    "\n",
    "gpu_helper.init_cuda_torch(UUIDs, f\"{DATA_ROOT}/core-kind/yinwang\")\n",
    "\n",
    "model_map = {\n",
    "   \"small\": \"google/mt5-small\", # 1.2 GB\n",
    "   \"base\" : \"google/mt5-base\", # 2.33 GB\n",
    "   \"large\" : \"google/mt5-large\", # 4.9 GB,\n",
    "   \"xl\" : \"google/mt5-xl\", # 15 GB\n",
    "   \"xxl\" : \"google/mt5-xxl\", # 51.7 GB,\n",
    "   \"custom\": \"Helsinki-NLP/opus-mt-de-en\", \n",
    "}\n",
    "\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "print(os.environ[\"XDG_CACHE_HOME\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea74988-7764-41a6-ae20-a685d708bed9",
   "metadata": {},
   "source": [
    "## Setting up translation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80fe33ad-666c-4794-9afa-c5b515458cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helsinki-NLP/opus-mt-de-en\n"
     ]
    }
   ],
   "source": [
    "model_type = \"custom\"\n",
    "model_name = model_map.get(model_type, \"small\")\n",
    "\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bb65c33-4b8c-466f-985a-3f8d7789d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "068283d6-c0a3-414a-a5ab-71a39978fbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "device_map=\"auto\" doesn't work with \"Helsinki-NLP/opus-mt-de-en\" translator model\n",
    "use explicit gpu device id 0 with device=0\n",
    "'''\n",
    "generator = pipeline(\n",
    "    \"translation\", \n",
    "    model=model_name,\n",
    "    # device_map=\"auto\",\n",
    "    device=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35516616-a921-419e-80df-276ed6685e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24cc4e14-da3c-4b3a-a9e0-a1abb4e7f6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_prefix = \"translate English to German: \"\n",
    "# task_prefix = \"translate German to English: \"\n",
    "# task_prefix = \"Ã¼bersetze Deutsch zum Englisch: \"\n",
    "# Reference: https://huggingface.co/docs/transformers/model_doc/marian\n",
    "def translate_gen(\n",
    "    generator: transformers.pipelines.text2text_generation.TranslationPipeline, \n",
    "    info: AcceleratorStatus,\n",
    "):  \n",
    "    \"\"\"\n",
    "    Args:\n",
    "      max_new_tokens: control the maximum length of the generation\n",
    "    \"\"\"\n",
    "    \n",
    "    def local(sentences: list, max_length=400, verbose: bool = True) -> list:\n",
    "        \"\"\"single input, no batch input\n",
    "        Args:\n",
    "          sentences:\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        \n",
    "        result = generator(\n",
    "            sentences, \n",
    "            max_length=max_length,\n",
    "            # return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        end = time.time()\n",
    "        duration = end - start\n",
    "        if verbose:\n",
    "            print(\"-\"*20)\n",
    "            print(f\"walltime: {duration} in secs.\")\n",
    "            info.gpu_usage()\n",
    "        \n",
    "        return result\n",
    "    return local    \n",
    "\n",
    "translate = translate_gen(generator, gpu_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "488da92f-4200-4f40-ac47-fe0db1da39a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input=[\"Das Haus ist wunderbar.\"]\n",
    "# input=\"Das Haus ist wunderbar.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "887eded6-4d0a-4bba-822e-c66d2a690bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "walltime: 0.7340705394744873 in secs.\n",
      "num_of_gpus: 1\n",
      "--------------------\n",
      "Device name      : NVIDIA A100 80GB PCIe MIG 2g.20gb \n",
      "Device idx       : 0 \n",
      "No. of processors: 28\n",
      "Physical  memory : 19.500000 GB\n",
      "Reserved  memory : 0.310547 GB\n",
      "Allocated memory : 0.285861 GB\n",
      "Free      memory : 0.024686 GB\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'The house is wonderful.'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit\n",
    "translate(input, max_length=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b7f373-31d3-4332-a985-275ae1ca29e1",
   "metadata": {},
   "source": [
    "## Loading pdf content from s3 buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6671d13-1d08-489a-bfd8-16620ab29ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e66de078-f326-4bdd-9bf0-840150f64e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.objectstore_utils import S3BucketHelper, S3AccessConf\n",
    "\n",
    "s3_conf = S3AccessConf(\n",
    "    bucket_name = \"scivias-medreports\",\n",
    "    access_key_id = os.environ.get('AWS_ACCESS_KEY_ID'),\n",
    "    secret_access_key = os.environ.get('AWS_SECRET_ACCESS_KEY'),\n",
    "    endpoint = os.environ.get('S3_ENDPOINT'),\n",
    "    verify_host = True\n",
    ")\n",
    "\n",
    "\n",
    "bucket_helper = S3BucketHelper(conf=s3_conf, file_prefix=\"KK-SCIVIAS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d94edea4-f148-4ca9-890c-5dca8e283ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# items_max_limit = -1\n",
    "items_max_limit = 2\n",
    "item_map = bucket_helper.get_object_keys(items_max_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23c1716c-aac4-4d3b-bba9-fed3ec17c8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_list = list(item_map)\n",
    "# len(item_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb76e747-1795-404c-a275-70692bb97e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pdf_reader(id_bytes: dict):\n",
    "    return {\n",
    "        \"name\" : id_bytes.get('name'),\n",
    "        \"reader\" : PdfReader(id_bytes.get('bytesio')) \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bae61cfa-cb90-45e1-96c1-935b3ba8f69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_map = bucket_helper.transform_objects(item_map, create_pdf_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d3bca20-b899-4ea8-b70e-d2e5e1edb1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf_pages(id_reader: dict) -> dict:\n",
    "    '''\n",
    "    one pdf page can have till 2.5K token, need to join and then split\n",
    "    '''\n",
    "    # return [page.extract_text() for page in reader.pages]\n",
    "    return {\n",
    "        \"name\": id_reader.get('name'),\n",
    "        \"content\" : \"\".join([page.extract_text() for page in id_reader.get('reader').pages])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72e8310c-5c97-409d-956c-1d6582633fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pdf_map = map(read_pdf_pages, reader_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74b62873-f582-4496-9a2e-b60b096f7de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/13673060/split-string-into-strings-by-length\n",
    "def wrap(name, s, w):\n",
    "    \"\"\"\n",
    "    split string with length w into a list of strings with length w\n",
    "    Arge:\n",
    "      s: orginial str\n",
    "      w: with of the each split for the string\n",
    "      \n",
    "    Return:\n",
    "      a list of string with each element as string of length w\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"pages\": [s[i:i + w] for i in range(0, len(s), w)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2f17b60-e0f1-411a-87cb-6e04da1bfa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_pages_map = map(lambda x: wrap(x.get('name'), x.get('content'), 350), raw_pdf_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2c78cfb-aad6-4be4-8d22-bb17fc6418c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of pdf documents, each item is a list representing the 350 token split of a docuemnt\n",
    "# doc_list = list(pdf_pages_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e46440a1-d8d8-472b-81e2-d1b7ade814e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_0_doc_0 = doc_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ace22c5f-6350-494e-bc23-19381e1771a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(split_0_doc_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3702722b-7c7b-4d32-8d7f-cf789b69a798",
   "metadata": {},
   "source": [
    "## Translate the max-token splitted documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be4a73e3-dc5d-4d4c-832c-4de69fd599e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_document(splitted_doc: dict) -> str:\n",
    "    output = []\n",
    "    for input in splitted_doc.get('pages'):\n",
    "        output.append(translate(input, verbose=False)[0].get('translation_text', '').strip())\n",
    "    return {\n",
    "        \"name\" : splitted_doc.get('name'),\n",
    "        \"content\" : ''.join(output)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f1bcc51-78d1-43d6-b8b7-3c0857f8811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_doc_map = map(translate_document, pdf_pages_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc8ac030-5103-467d-8cc7-c24ba1013981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start = time.time()\n",
    "#en_doc_dict_list = list(translated_doc_map)\n",
    "#end = time.time()\n",
    "#duration = end - start\n",
    "#print(\"-\"*20)\n",
    "#print(f\"walltime: {duration} in secs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f25f519-f2db-400f-b263-e836f2e4fdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 docs in one min\n",
    "# total_mins = int(250 / 3)\n",
    "# total_hours = int(total_mins/60) + 1\n",
    "# print(total_mins)\n",
    "# print(total_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a414fa2-295d-4e04-9fd6-52b466abd878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the tranlated document token size\n",
    "#for en_doc in en_doc_dict_list:\n",
    "#    print(en_doc.get('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "993d2935-9901-414c-abc4-d21a74dd5df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for en_doc in en_doc_dict_list:\n",
    "#    print(f\"no. of token: {len(en_doc.get('content'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb0eeb39-80a9-4475-94bc-401abc69b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(en_doc_dict_list[0].get('name'))\n",
    "#print(en_doc_dict_list[2].get('content'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5235101-a39d-40a5-aec4-3f7ded812077",
   "metadata": {},
   "source": [
    "## Persist the translated docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "059d191a-0c17-437e-83c9-8c12d2c7dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_s3_name(old_key: str) -> str:\n",
    "    return f\"trans2en/{old_key.replace('pdf', 'txt')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3f841ef-06d3-4ddc-9022-d900e3f6cbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_s3_name(en_doc_dict_list[0].get('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "855b47b5-f967-42ce-9f82-b3e6c5efb805",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_action_map =bucket_helper.upload_objects(translated_doc_map, create_s3_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "905a2250-8d56-4b8a-810c-1cce809c8921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "walltime: 33.82029724121094 in secs.\n"
     ]
    }
   ],
   "source": [
    "# need to use list to trigger the map reactive call for the map generator pipeline\n",
    "start = time.time()\n",
    "upload_action_list = list(upload_action_map)\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "print(\"-\"*20)\n",
    "print(f\"walltime: {duration} in secs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52dea4bd-4cab-4391-800a-d78885f21442",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload_action_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b41e954-7d9b-48b9-a8ae-98e1071c3e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
