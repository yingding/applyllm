{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dce6ec1-4e23-4d4c-b2b7-6c2de9b465c5",
   "metadata": {},
   "source": [
    "# Language Translation with mT5 or T5 \n",
    "\n",
    "## English to German with T5\n",
    "* T5 https://huggingface.co/docs/transformers/model_doc/t5\n",
    "* Translation intro course https://huggingface.co/learn/nlp-course/chapter7/4?fw=tf\n",
    "* Two way translation with T5 discussion: https://stackoverflow.com/questions/66797042/using-googles-t5-for-translation-from-german-to-english\n",
    "* Model capability output example: https://github.com/PacktPublishing/Transformers-for-Natural-Language-Processing/blob/main/Chapter07/Summarizing_Text_with_T5.ipynb\n",
    "\n",
    "\n",
    "## German to English with mT5\n",
    "* https://huggingface.co/docs/transformers/model_doc/mt5\n",
    "* https://huggingface.co/docs/transformers/model_doc/mt5#transformers.MT5ForConditionalGeneration\n",
    "* https://huggingface.co/transformers/v4.9.2/model_doc/mt5.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d85ef3af-bda8-435c-96cd-55ff0ae716dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA A100 80GB PCIe (UUID: GPU-51f84540-9ebb-1d44-7bb7-3c62ae55c20e)\n",
      "  MIG 2g.20gb     Device  0: (UUID: MIG-f1e32298-70d4-52fc-9b1d-21a178d44529)\n"
     ]
    }
   ],
   "source": [
    "list=!nvidia-smi -L\n",
    "for i in range(len(list)):\n",
    "    print(list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4e9f28f-d517-44fc-a91e-832ee2516760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIG-f1e32298-70d4-52fc-9b1d-21a178d44529\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def get_device_uuid(input: str) -> str:\n",
    "    try:\n",
    "        # r'' before the search pattern indicates it is a raw string, \n",
    "        # otherwise \"\" instead of single quote\n",
    "        uuid = re.search(r'UUID\\:\\s(.+?)\\)', input).group(1)\n",
    "    except AttributeError:\n",
    "        # \"UUID\\:\\s\" and \"\\)\" not found\n",
    "        uuid = \"\"\n",
    "    return uuid    \n",
    "\n",
    "# skip the first GPU ID, only get the MIG IDs, using python list slice over index access\n",
    "uuid_list = [get_device_uuid(e) for e in list[1:]]\n",
    "# print(uuid_list)\n",
    "UUIDs = \",\".join(uuid_list)\n",
    "print(UUIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c714714-0c21-499d-af92-be62f99e83a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIG-f1e32298-70d4-52fc-9b1d-21a178d44529\n",
      "3.8.10\n"
     ]
    }
   ],
   "source": [
    "import os, time, sys\n",
    "from platform import python_version\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = UUIDs # \"0,1,2\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\" #512\n",
    "display_architecture=True\n",
    "\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc8923a3-d0e5-494e-86de-a0eeb0de80e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the model download cache directory\n",
    "# DATA_ROOT=\"/data\"\n",
    "DATA_ROOT=\"/home/jovyan/llm-models\"\n",
    "os.environ['XDG_CACHE_HOME']=f\"{DATA_ROOT}/core-kind/yinwang/models\"\n",
    "\n",
    "model_map = {\n",
    "   \"small\": \"google/mt5-small\", # 1.2 GB\n",
    "   \"base\" : \"google/mt5-base\", # 2.33 GB\n",
    "   \"large\" : \"google/mt5-large\", # 4.9 GB,\n",
    "   \"xl\" : \"google/mt5-xl\", # 15 GB\n",
    "   \"xxl\" : \"google/mt5-xxl\", # 51.7 GB,\n",
    "   \"custom\": \"Helsinki-NLP/opus-mt-de-en\", \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80fe33ad-666c-4794-9afa-c5b515458cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helsinki-NLP/opus-mt-de-en\n"
     ]
    }
   ],
   "source": [
    "# model_type = \"xl\"\n",
    "# model_type = \"small\"\n",
    "model_type = \"custom\"\n",
    "model_name = model_map.get(model_type, \"small\")\n",
    "\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8286b2db-c705-4e0b-ae69-1f9de69e310e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "# T5\n",
    "# from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "\n",
    "# mT5\n",
    "# from transformers import MT5Model, MT5ForConditionalGeneration, MT5TokenizerFast, MT5Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45468974-afe0-48e5-ae87-efa592348932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = T5Tokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "# tokenizer = MT5TokenizerFast.from_pretrained(model_name)\n",
    "# type(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5bb65c33-4b8c-466f-985a-3f8d7789d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "068283d6-c0a3-414a-a5ab-71a39978fbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = pipeline(\n",
    "    \"translation\", \n",
    "    model=\"Helsinki-NLP/opus-mt-de-en\",\n",
    "    # torch_dtype=torch.float16,\n",
    "    # device_map=\"auto\",\n",
    "    device=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc77e15b-3efe-499a-b1b5-f813049ddc04",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MT5ForConditionalGeneration' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model = T5ForConditionalGeneration.from_pretrained(model_name)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMT5ForConditionalGeneration\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MT5ForConditionalGeneration' is not defined"
     ]
    }
   ],
   "source": [
    "# model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "# model = MT5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1a4eeb2-274b-45a2-a113-6a62e606344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71af5aef-f619-4c35-ad11-108bf1ca9af9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MT5Config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m display_architecture \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mMT5Config\u001b[49m(model\u001b[38;5;241m.\u001b[39mconfig))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MT5Config' is not defined"
     ]
    }
   ],
   "source": [
    "if display_architecture == True:\n",
    "    print(MT5Config(model.config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7f04a349-f323-4b57-a674-37817f2a57fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if display_architecture == True:\n",
    "#    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea74988-7764-41a6-ae20-a685d708bed9",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "* max_new_tokens ?\n",
    "\n",
    "```console\n",
    "/home/jovyan/.local/lib/python3.8/site-packages/transformers/generation/utils.py:1254: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "24cc4e14-da3c-4b3a-a9e0-a1abb4e7f6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.gpu_utils import GPUInfoHelper\n",
    "\n",
    "gpu_info_helper = GPUInfoHelper()\n",
    "# task_prefix = \"translate English to German: \"\n",
    "task_prefix = \"translate German to English: \"\n",
    "# task_prefix = \"Ã¼bersetze Deutsch zum Englisch: \"\n",
    "\n",
    "def translate_gen(\n",
    "    model: transformers.models.t5.modeling_t5.T5ForConditionalGeneration, \n",
    "    tokenizer: transformers.models.t5.tokenization_t5_fast.T5TokenizerFast,\n",
    "    info: GPUInfoHelper,\n",
    "    task_prefix: str = \"translate English to German: \"\n",
    "):  \n",
    "    \"\"\"\n",
    "    Args:\n",
    "      max_new_tokens: control the maximum length of the generation\n",
    "    \"\"\"\n",
    "    \n",
    "    def local(input: str) -> str:\n",
    "        \"\"\"single input, no batch input\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        \n",
    "        sentence = task_prefix + input\n",
    "        \n",
    "        input_ids = tokenizer(sentence, return_tensors=\"pt\").input_ids\n",
    "        outputs = model.generate(input_ids)\n",
    "        result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        end = time.time()\n",
    "        duration = end - start\n",
    "        print(\"-\"*20)\n",
    "        print(f\"walltime: {duration} in secs.\")\n",
    "        info.gpu_usage()\n",
    "        \n",
    "        return result\n",
    "    return local    \n",
    "\n",
    "translate = translate_gen(model, tokenizer, info=gpu_info_helper, task_prefix=task_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "488da92f-4200-4f40-ac47-fe0db1da39a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input=\"Das Haus ist wunderbar.\"\n",
    "# input=\"The house is wonderful.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "887eded6-4d0a-4bba-822e-c66d2a690bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "walltime: 0.5482296943664551 in secs.\n",
      "num_of_gpus: 1\n",
      "--------------------\n",
      "Device_name      : NVIDIA A100 80GB PCIe MIG 2g.20gb \n",
      "Multi_processor  : 28\n",
      "Physical  memory : 19.500000 GB\n",
      "Reserved  memory : 0.000000 GB\n",
      "Allocated memory : 0.000000 GB\n",
      "Free      memory : 0.000000 GB\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<extra_id_0>'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2d3a3f-1697-4f9d-8d01-cd163bfe16f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
