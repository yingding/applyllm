{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9302288-5f83-403a-81e4-d1cc15e28272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afb58e2b-6559-4db3-9ebc-95ef05f2b151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!cat ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c70a197-b4a8-41af-9030-706699ef557e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!{sys.executable} -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "608244d5-b5e5-4740-b44e-81ea0d67ca08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/jovyan/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -otocore (/home/jovyan/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/jovyan/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -otocore (/home/jovyan/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: huggingface_hub==0.20.2 in /home/jovyan/.local/lib/python3.8/site-packages (from -r ./requirements.txt (line 1)) (0.20.2)\n",
      "Requirement already satisfied: transformers==4.36.2 in /home/jovyan/.local/lib/python3.8/site-packages (from -r ./requirements.txt (line 4)) (4.36.2)\n",
      "Requirement already satisfied: urllib3==1.26.16 in /home/jovyan/.local/lib/python3.8/site-packages (from -r ./requirements.txt (line 11)) (1.26.16)\n",
      "Requirement already satisfied: jsonschema==4.19.0 in /home/jovyan/.local/lib/python3.8/site-packages (from -r ./requirements.txt (line 12)) (4.19.0)\n",
      "Requirement already satisfied: fastai==2.7.13 in /home/jovyan/.local/lib/python3.8/site-packages (from -r ./requirements.txt (line 13)) (2.7.13)\n",
      "Requirement already satisfied: ipywidgets==8.1.0 in /home/jovyan/.local/lib/python3.8/site-packages (from -r ./requirements.txt (line 15)) (8.1.0)\n",
      "Requirement already satisfied: click==8.1.7 in /home/jovyan/.local/lib/python3.8/site-packages (from -r ./requirements.txt (line 17)) (8.1.7)\n",
      "Requirement already satisfied: multipledispatch==1.0.0 in /home/jovyan/.local/lib/python3.8/site-packages (from -r ./requirements.txt (line 29)) (1.0.0)\n",
      "Requirement already satisfied: sentencepiece==0.1.99 in /home/jovyan/.local/lib/python3.8/site-packages (from -r ./requirements.txt (line 31)) (0.1.99)\n",
      "Requirement already satisfied: sacremoses==0.0.53 in /home/jovyan/.local/lib/python3.8/site-packages (from -r ./requirements.txt (line 34)) (0.0.53)\n",
      "Requirement already satisfied: pypdf==3.15.5 in /home/jovyan/.local/lib/python3.8/site-packages (from -r ./requirements.txt (line 36)) (3.15.5)\n",
      "Requirement already satisfied: accelerate==0.26.1 in /home/jovyan/.local/lib/python3.8/site-packages (from -r ./requirements.txt (line 42)) (0.26.1)\n",
      "Requirement already satisfied: torch==2.1.2+cu118 in /home/jovyan/.local/lib/python3.8/site-packages (from -r ./requirements.txt (line 46)) (2.1.2+cu118)\n",
      "Requirement already satisfied: torchaudio==2.1.2+cu118 in /home/jovyan/.local/lib/python3.8/site-packages (from -r ./requirements.txt (line 47)) (2.1.2+cu118)\n",
      "Requirement already satisfied: torchvision==0.16.2+cu118 in /home/jovyan/.local/lib/python3.8/site-packages (from -r ./requirements.txt (line 48)) (0.16.2+cu118)\n",
      "Requirement already satisfied: xformers==0.0.23.post1+cu118 in /home/jovyan/.local/lib/python3.8/site-packages (from -r ./requirements.txt (line 49)) (0.0.23.post1+cu118)\n",
      "Requirement already satisfied: langchain==0.1.0 in /home/jovyan/.local/lib/python3.8/site-packages (from -r ./requirements.txt (line 56)) (0.1.0)\n",
      "Requirement already satisfied: pydantic==1.10.13 in /home/jovyan/.local/lib/python3.8/site-packages (from -r ./requirements.txt (line 61)) (1.10.13)\n",
      "Requirement already satisfied: unstructured==0.11.0 in /home/jovyan/.local/lib/python3.8/site-packages (from -r ./requirements.txt (line 64)) (0.11.0)\n",
      "Requirement already satisfied: sentence-transformers==2.2.2 in /home/jovyan/.local/lib/python3.8/site-packages (from -r ./requirements.txt (line 65)) (2.2.2)\n",
      "Requirement already satisfied: docarray==0.39.1 in /home/jovyan/.local/lib/python3.8/site-packages (from -r ./requirements.txt (line 66)) (0.39.1)\n",
      "Requirement already satisfied: boto3==1.34.14 in /home/jovyan/.local/lib/python3.8/site-packages (from -r ./requirements.txt (line 72)) (1.34.14)\n",
      "Requirement already satisfied: filelock in /home/jovyan/.local/lib/python3.8/site-packages (from huggingface_hub==0.20.2->-r ./requirements.txt (line 1)) (3.12.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jovyan/.local/lib/python3.8/site-packages (from huggingface_hub==0.20.2->-r ./requirements.txt (line 1)) (2023.9.0)\n",
      "Requirement already satisfied: requests in /home/jovyan/.local/lib/python3.8/site-packages (from huggingface_hub==0.20.2->-r ./requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.8/site-packages (from huggingface_hub==0.20.2->-r ./requirements.txt (line 1)) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from huggingface_hub==0.20.2->-r ./requirements.txt (line 1)) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jovyan/.local/lib/python3.8/site-packages (from huggingface_hub==0.20.2->-r ./requirements.txt (line 1)) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/jovyan/.local/lib/python3.8/site-packages (from huggingface_hub==0.20.2->-r ./requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.36.2->-r ./requirements.txt (line 4)) (1.22.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jovyan/.local/lib/python3.8/site-packages (from transformers==4.36.2->-r ./requirements.txt (line 4)) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/jovyan/.local/lib/python3.8/site-packages (from transformers==4.36.2->-r ./requirements.txt (line 4)) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/jovyan/.local/lib/python3.8/site-packages (from transformers==4.36.2->-r ./requirements.txt (line 4)) (0.3.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema==4.19.0->-r ./requirements.txt (line 12)) (22.2.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema==4.19.0->-r ./requirements.txt (line 12)) (5.12.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/jovyan/.local/lib/python3.8/site-packages (from jsonschema==4.19.0->-r ./requirements.txt (line 12)) (2023.7.1)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/conda/lib/python3.8/site-packages (from jsonschema==4.19.0->-r ./requirements.txt (line 12)) (1.3.10)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/jovyan/.local/lib/python3.8/site-packages (from jsonschema==4.19.0->-r ./requirements.txt (line 12)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/jovyan/.local/lib/python3.8/site-packages (from jsonschema==4.19.0->-r ./requirements.txt (line 12)) (0.10.2)\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.8/site-packages (from fastai==2.7.13->-r ./requirements.txt (line 13)) (23.3.2)\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in /home/jovyan/.local/lib/python3.8/site-packages (from fastai==2.7.13->-r ./requirements.txt (line 13)) (0.0.7)\n",
      "Requirement already satisfied: fastcore<1.6,>=1.5.29 in /home/jovyan/.local/lib/python3.8/site-packages (from fastai==2.7.13->-r ./requirements.txt (line 13)) (1.5.29)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from fastai==2.7.13->-r ./requirements.txt (line 13)) (3.4.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from fastai==2.7.13->-r ./requirements.txt (line 13)) (1.2.4)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.8/site-packages (from fastai==2.7.13->-r ./requirements.txt (line 13)) (1.0.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.8/site-packages (from fastai==2.7.13->-r ./requirements.txt (line 13)) (9.4.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from fastai==2.7.13->-r ./requirements.txt (line 13)) (0.24.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from fastai==2.7.13->-r ./requirements.txt (line 13)) (1.7.0)\n",
      "Requirement already satisfied: spacy<4 in /home/jovyan/.local/lib/python3.8/site-packages (from fastai==2.7.13->-r ./requirements.txt (line 13)) (3.7.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/jovyan/.local/lib/python3.8/site-packages (from ipywidgets==8.1.0->-r ./requirements.txt (line 15)) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets==8.1.0->-r ./requirements.txt (line 15)) (8.11.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets==8.1.0->-r ./requirements.txt (line 15)) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /home/jovyan/.local/lib/python3.8/site-packages (from ipywidgets==8.1.0->-r ./requirements.txt (line 15)) (4.0.8)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /home/jovyan/.local/lib/python3.8/site-packages (from ipywidgets==8.1.0->-r ./requirements.txt (line 15)) (3.0.8)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses==0.0.53->-r ./requirements.txt (line 34)) (1.16.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses==0.0.53->-r ./requirements.txt (line 34)) (1.2.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from accelerate==0.26.1->-r ./requirements.txt (line 42)) (5.9.4)\n",
      "Requirement already satisfied: sympy in /home/jovyan/.local/lib/python3.8/site-packages (from torch==2.1.2+cu118->-r ./requirements.txt (line 46)) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2+cu118->-r ./requirements.txt (line 46)) (3.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2+cu118->-r ./requirements.txt (line 46)) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/jovyan/.local/lib/python3.8/site-packages (from torch==2.1.2+cu118->-r ./requirements.txt (line 46)) (2.1.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/jovyan/.local/lib/python3.8/site-packages (from langchain==0.1.0->-r ./requirements.txt (line 56)) (2.0.24)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/jovyan/.local/lib/python3.8/site-packages (from langchain==0.1.0->-r ./requirements.txt (line 56)) (3.9.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/jovyan/.local/lib/python3.8/site-packages (from langchain==0.1.0->-r ./requirements.txt (line 56)) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/jovyan/.local/lib/python3.8/site-packages (from langchain==0.1.0->-r ./requirements.txt (line 56)) (0.6.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/jovyan/.local/lib/python3.8/site-packages (from langchain==0.1.0->-r ./requirements.txt (line 56)) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.9 in /home/jovyan/.local/lib/python3.8/site-packages (from langchain==0.1.0->-r ./requirements.txt (line 56)) (0.0.10)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.7 in /home/jovyan/.local/lib/python3.8/site-packages (from langchain==0.1.0->-r ./requirements.txt (line 56)) (0.1.8)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.77 in /home/jovyan/.local/lib/python3.8/site-packages (from langchain==0.1.0->-r ./requirements.txt (line 56)) (0.0.77)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/jovyan/.local/lib/python3.8/site-packages (from langchain==0.1.0->-r ./requirements.txt (line 56)) (8.2.3)\n",
      "Requirement already satisfied: chardet in /home/jovyan/.local/lib/python3.8/site-packages (from unstructured==0.11.0->-r ./requirements.txt (line 64)) (5.2.0)\n",
      "Requirement already satisfied: filetype in /home/jovyan/.local/lib/python3.8/site-packages (from unstructured==0.11.0->-r ./requirements.txt (line 64)) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /home/jovyan/.local/lib/python3.8/site-packages (from unstructured==0.11.0->-r ./requirements.txt (line 64)) (0.4.27)\n",
      "Requirement already satisfied: lxml in /home/jovyan/.local/lib/python3.8/site-packages (from unstructured==0.11.0->-r ./requirements.txt (line 64)) (4.9.3)\n",
      "Requirement already satisfied: nltk in /home/jovyan/.local/lib/python3.8/site-packages (from unstructured==0.11.0->-r ./requirements.txt (line 64)) (3.8.1)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.8/site-packages (from unstructured==0.11.0->-r ./requirements.txt (line 64)) (0.9.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/jovyan/.local/lib/python3.8/site-packages (from unstructured==0.11.0->-r ./requirements.txt (line 64)) (4.12.2)\n",
      "Requirement already satisfied: emoji in /home/jovyan/.local/lib/python3.8/site-packages (from unstructured==0.11.0->-r ./requirements.txt (line 64)) (2.8.0)\n",
      "Requirement already satisfied: python-iso639 in /home/jovyan/.local/lib/python3.8/site-packages (from unstructured==0.11.0->-r ./requirements.txt (line 64)) (2023.6.15)\n",
      "Requirement already satisfied: langdetect in /home/jovyan/.local/lib/python3.8/site-packages (from unstructured==0.11.0->-r ./requirements.txt (line 64)) (1.0.9)\n",
      "Requirement already satisfied: rapidfuzz in /home/jovyan/.local/lib/python3.8/site-packages (from unstructured==0.11.0->-r ./requirements.txt (line 64)) (3.5.2)\n",
      "Requirement already satisfied: backoff in /home/jovyan/.local/lib/python3.8/site-packages (from unstructured==0.11.0->-r ./requirements.txt (line 64)) (2.2.1)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.8/site-packages (from unstructured==0.11.0->-r ./requirements.txt (line 64)) (1.15.0)\n",
      "Requirement already satisfied: orjson>=3.8.2 in /home/jovyan/.local/lib/python3.8/site-packages (from docarray==0.39.1->-r ./requirements.txt (line 66)) (3.9.10)\n",
      "Requirement already satisfied: rich>=13.1.0 in /home/jovyan/.local/lib/python3.8/site-packages (from docarray==0.39.1->-r ./requirements.txt (line 66)) (13.7.0)\n",
      "Requirement already satisfied: types-requests>=2.28.11.6 in /home/jovyan/.local/lib/python3.8/site-packages (from docarray==0.39.1->-r ./requirements.txt (line 66)) (2.31.0.6)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/jovyan/.local/lib/python3.8/site-packages (from docarray==0.39.1->-r ./requirements.txt (line 66)) (0.9.0)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.14 in /home/jovyan/.local/lib/python3.8/site-packages (from boto3==1.34.14->-r ./requirements.txt (line 72)) (1.34.14)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/jovyan/.local/lib/python3.8/site-packages (from boto3==1.34.14->-r ./requirements.txt (line 72)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/jovyan/.local/lib/python3.8/site-packages (from boto3==1.34.14->-r ./requirements.txt (line 72)) (0.10.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jovyan/.local/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0->-r ./requirements.txt (line 56)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/jovyan/.local/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0->-r ./requirements.txt (line 56)) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jovyan/.local/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0->-r ./requirements.txt (line 56)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jovyan/.local/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0->-r ./requirements.txt (line 56)) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.8/site-packages (from botocore<1.35.0,>=1.34.14->boto3==1.34.14->-r ./requirements.txt (line 72)) (2.8.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/jovyan/.local/lib/python3.8/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.0->-r ./requirements.txt (line 56)) (3.20.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema==4.19.0->-r ./requirements.txt (line 12)) (3.15.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets==8.1.0->-r ./requirements.txt (line 15)) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets==8.1.0->-r ./requirements.txt (line 15)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets==8.1.0->-r ./requirements.txt (line 15)) (0.18.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets==8.1.0->-r ./requirements.txt (line 15)) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets==8.1.0->-r ./requirements.txt (line 15)) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets==8.1.0->-r ./requirements.txt (line 15)) (3.0.38)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets==8.1.0->-r ./requirements.txt (line 15)) (2.14.0)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets==8.1.0->-r ./requirements.txt (line 15)) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets==8.1.0->-r ./requirements.txt (line 15)) (4.8.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/jovyan/.local/lib/python3.8/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.0->-r ./requirements.txt (line 56)) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/conda/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1.7->langchain==0.1.0->-r ./requirements.txt (line 56)) (3.6.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface_hub==0.20.2->-r ./requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface_hub==0.20.2->-r ./requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface_hub==0.20.2->-r ./requirements.txt (line 1)) (2022.12.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jovyan/.local/lib/python3.8/site-packages (from rich>=13.1.0->docarray==0.39.1->-r ./requirements.txt (line 66)) (3.0.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.8/site-packages (from spacy<4->fastai==2.7.13->-r ./requirements.txt (line 13)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from spacy<4->fastai==2.7.13->-r ./requirements.txt (line 13)) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.8/site-packages (from spacy<4->fastai==2.7.13->-r ./requirements.txt (line 13)) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from spacy<4->fastai==2.7.13->-r ./requirements.txt (line 13)) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from spacy<4->fastai==2.7.13->-r ./requirements.txt (line 13)) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /home/jovyan/.local/lib/python3.8/site-packages (from spacy<4->fastai==2.7.13->-r ./requirements.txt (line 13)) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.8/site-packages (from spacy<4->fastai==2.7.13->-r ./requirements.txt (line 13)) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.8/site-packages (from spacy<4->fastai==2.7.13->-r ./requirements.txt (line 13)) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.8/site-packages (from spacy<4->fastai==2.7.13->-r ./requirements.txt (line 13)) (2.0.8)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/jovyan/.local/lib/python3.8/site-packages (from spacy<4->fastai==2.7.13->-r ./requirements.txt (line 13)) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from spacy<4->fastai==2.7.13->-r ./requirements.txt (line 13)) (0.7.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.8/site-packages (from spacy<4->fastai==2.7.13->-r ./requirements.txt (line 13)) (6.3.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from spacy<4->fastai==2.7.13->-r ./requirements.txt (line 13)) (67.6.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.8/site-packages (from spacy<4->fastai==2.7.13->-r ./requirements.txt (line 13)) (3.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/jovyan/.local/lib/python3.8/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.0->-r ./requirements.txt (line 56)) (3.0.1)\n",
      "Requirement already satisfied: types-urllib3 in /home/jovyan/.local/lib/python3.8/site-packages (from types-requests>=2.28.11.6->docarray==0.39.1->-r ./requirements.txt (line 66)) (1.26.25.14)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/jovyan/.local/lib/python3.8/site-packages (from typing-inspect>=0.8.0->docarray==0.39.1->-r ./requirements.txt (line 66)) (1.0.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.8/site-packages (from beautifulsoup4->unstructured==0.11.0->-r ./requirements.txt (line 64)) (2.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch==2.1.2+cu118->-r ./requirements.txt (line 46)) (2.1.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->fastai==2.7.13->-r ./requirements.txt (line 13)) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->fastai==2.7.13->-r ./requirements.txt (line 13)) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->fastai==2.7.13->-r ./requirements.txt (line 13)) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas->fastai==2.7.13->-r ./requirements.txt (line 13)) (2023.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->fastai==2.7.13->-r ./requirements.txt (line 13)) (3.1.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/jovyan/.local/lib/python3.8/site-packages (from sympy->torch==2.1.2+cu118->-r ./requirements.txt (line 46)) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.8/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain==0.1.0->-r ./requirements.txt (line 56)) (1.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.1.0->-r ./requirements.txt (line 15)) (0.8.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jovyan/.local/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray==0.39.1->-r ./requirements.txt (line 66)) (0.1.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets==8.1.0->-r ./requirements.txt (line 15)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets==8.1.0->-r ./requirements.txt (line 15)) (0.2.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.8/site-packages (from thinc<8.3.0,>=8.1.8->spacy<4->fastai==2.7.13->-r ./requirements.txt (line 13)) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/jovyan/.local/lib/python3.8/site-packages (from thinc<8.3.0,>=8.1.8->spacy<4->fastai==2.7.13->-r ./requirements.txt (line 13)) (0.1.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/jovyan/.local/lib/python3.8/site-packages (from weasel<0.4.0,>=0.1.0->spacy<4->fastai==2.7.13->-r ./requirements.txt (line 13)) (0.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets==8.1.0->-r ./requirements.txt (line 15)) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets==8.1.0->-r ./requirements.txt (line 15)) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets==8.1.0->-r ./requirements.txt (line 15)) (0.2.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/jovyan/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -otocore (/home/jovyan/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/jovyan/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -otocore (/home/jovyan/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/jovyan/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -otocore (/home/jovyan/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/jovyan/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -otocore (/home/jovyan/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install --user --upgrade -r ./requirements.txt --extra-index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cbbc3d6-9d67-4a4c-84a9-e2e1c75351b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48662e9c-04da-455f-a80d-bd8136ee5f2e",
   "metadata": {},
   "source": [
    "#### Useful installation for KF notebook 1.7.0 cu111 drivers\n",
    "\n",
    "```shell\n",
    "#!{sys.executable} -m pip install --user --upgrade transformers==4.31.0\n",
    "#!{sys.executable} -m pip install --user --upgrade torch==1.10.2+cu111 fastai==2.7.12 fastcore==1.5.29 fastdownload==0.0.7 torchvision==0.11.3+cu111 --extra-index-url https://download.pytorch.org/whl/cu111\n",
    "#!{sys.executable} -m pip install --user --upgrade accelerate==0.20.3\n",
    "```\n",
    "\n",
    "We shall use the cuda 11.8 version (Cuda118)\n",
    "```shell\n",
    "#!{sys.executable} -m pip install --user --upgrade torch==2.0.0+cu118 --extra-index-url https://download.pytorch.org/whl/cu118\n",
    "```\n",
    "`xformers==0.0.21` need `torch==2.0.1``\n",
    "```shell\n",
    "#!{sys.executable} -m pip install --user --upgrade xformers==0.0.21 torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2\n",
    "```\n",
    "\n",
    "show js loading with ipywidgets\n",
    "```shell\n",
    "#!{sys.executable} -m pip install --user --upgrade ipywidgets==8.1.0 comm==0.1.4 jupyterlab-widgets==3.0.8 widgetsnbextension==4.0.8\n",
    "```\n",
    "\n",
    "uninstall\n",
    "```shell\n",
    "#!{sys.executable} -m pip uninstall accelerator transformers xformers torch -y \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a7468a-cdc9-462f-98ab-c6b64d1be424",
   "metadata": {},
   "source": [
    "## (optional) restart kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fff70f6-cd4d-4298-91bf-c7c948e6fc72",
   "metadata": {},
   "source": [
    "### (optional) Set huggingface cli in terminal\n",
    "\n",
    "```shell\n",
    "PATH=${PATH}:/home/jupyter/.local/bin\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9795f7a-5be2-49dd-b889-d363885fddf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (optional) uncomment the following lines to set path in python notebook cell for notebook session \n",
    "# PATH=%env PATH\n",
    "# %env PATH={PATH}:/home/jupyter/.local/bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5607d79b-17bd-4290-84c5-136c817d41e3",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Multi GPU inference: https://github.com/tloen/alpaca-lora/issues/445\n",
    "\n",
    "Show accelerator device IDs:\n",
    "\n",
    "```shell\n",
    "nvidia-smi -L\n",
    "```\n",
    "\n",
    "Nvidia usage\n",
    "```shell\n",
    "nvidia-smi -q -g 0 -d UTILIZATION -l\n",
    "```\n",
    "\n",
    "python lib: gpustat\n",
    "```python\n",
    "gpustat -cp\n",
    "```\n",
    "\n",
    "* https://stackoverflow.com/questions/8223811/a-top-like-utility-for-monitoring-cuda-activity-on-a-gpu\n",
    "\n",
    "Check GPU info in PyTorch\n",
    "* https://stackoverflow.com/questions/48152674/how-do-i-check-if-pytorch-is-using-the-gpu\n",
    "* CUDA memory management https://pytorch.org/docs/stable/notes/cuda.html#cuda-memory-management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2627d00c-12e8-44c9-a62f-e0da1d0457e3",
   "metadata": {},
   "source": [
    "### Extract the GPU Accelerator MIG UUIDs\n",
    "\n",
    "* Extract with re.search and group: https://note.nkmk.me/en/python-str-extract/\n",
    "* Extract with pattern before and after: https://stackoverflow.com/questions/4666973/how-to-extract-the-substring-between-two-markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea92d003-03af-4750-9a15-85f2eb2cffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list=!nvidia-smi -L\n",
    "for i in range(len(list)):\n",
    "    print(list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76206acf-2f57-4460-b0cd-d94af56fa07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_device_uuid(input: str) -> str:\n",
    "    try:\n",
    "        # r'' before the search pattern indicates it is a raw string, \n",
    "        # otherwise \"\" instead of single quote\n",
    "        uuid = re.search(r'UUID\\:\\s(.+?)\\)', input).group(1)\n",
    "    except AttributeError:\n",
    "        # \"UUID\\:\\s\" and \"\\)\" not found\n",
    "        uuid = \"\"\n",
    "    return uuid    \n",
    "\n",
    "# skip the first GPU ID, only get the MIG IDs, using python list slice over index access\n",
    "uuid_list = [get_device_uuid(e) for e in list[1:]]\n",
    "# print(uuid_list)\n",
    "UUIDs = \",\".join(uuid_list)\n",
    "print(UUIDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8f7423-8550-48c4-96f7-54670ee9b632",
   "metadata": {},
   "source": [
    "### PyTorch distributed with device UUID\n",
    "* https://discuss.pytorch.org/t/world-size-and-rank-torch-distributed-init-process-group/57438"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5979a1e-9a9f-403a-9e0b-41e4dc4686f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, sys\n",
    "from platform import python_version\n",
    "# data volume mounted in kubeflow notebook\n",
    "DATA_ROOT=\"/home/jovyan/llm-models\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = UUIDs # \"0,1,2\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\" #512\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\" # for debugging\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"]=\"false\"\n",
    "os.environ['XDG_CACHE_HOME']=f\"{DATA_ROOT}/core-kind/yinwang/models\"\n",
    "\n",
    "\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7548a80-c908-4d3f-be5a-b39405036b61",
   "metadata": {},
   "source": [
    "#### CUDA MIG memory notice\n",
    "The following python command shall show the available MIG memory\n",
    "```shell\n",
    "print(torch.cuda.mem_get_info())\n",
    "for e in torch.cuda.mem_get_info():\n",
    "    print(e/1024**3)\n",
    "```\n",
    "The first tuple shows the availabe MIG cuda memory, if it goes to zero, and no process is attached,\n",
    "this means a cuda process is hang.\n",
    "```console\n",
    "(20748107776, 20937965568)\n",
    "19.32318115234375\n",
    "19.5\n",
    "```\n",
    "\n",
    "To terminate a cuda process, log into the GPU host\n",
    "```shell\n",
    "nvidia-smi # find out the PID something like 830333\n",
    "sudo kill -9 PID\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e320b2a-cac5-421a-abd5-036c6212b612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.mem_get_info())\n",
    "for e in torch.cuda.mem_get_info():\n",
    "    print(e/1024**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c0dfd5-9a5a-460a-a723-e62cad74536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/58216000/get-total-amount-of-free-gpu-memory-and-available-using-pytorch\n",
    "# torch.cuda.device_count()\n",
    "# t = torch.cuda.get_device_properties(0).total_memory\n",
    "# r = torch.cuda.memory_reserved(0)\n",
    "# a = torch.cuda.memory_allocated(0)\n",
    "# f = r-a  # free inside reserved\n",
    "# print(t/1024**3)\n",
    "# print(r/1024**3)\n",
    "# print(a/1024**3)\n",
    "# print(f/1024**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff43674-5abd-4da1-88d5-8c7daa6aca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://stackoverflow.com/questions/58216000/get-total-amount-of-free-gpu-memory-and-available-using-pytorch\n",
    "# from typing import Tuple\n",
    "\n",
    "def byte_gb_info(byte_mem) -> str:\n",
    "    \"\"\"calculate the byte size to GB size for better human readable\"\"\"\n",
    "    # format the f string float with :.2f to decimal digits\n",
    "    # https://zetcode.com/python/fstring/\n",
    "    return f\"{(byte_mem/1024**3):4f} GB\"\n",
    "\n",
    "\n",
    "def accelerator_mem_info(device_idx: int):\n",
    "    # total\n",
    "    t = torch.cuda.get_device_properties(device_idx).total_memory\n",
    "    # usable\n",
    "    r = torch.cuda.memory_reserved(device_idx)\n",
    "    # allocated\n",
    "    a = torch.cuda.memory_allocated(device_idx)\n",
    "    # still free\n",
    "    f = r-a\n",
    "    # unit = \"GB\"   \n",
    "    print( # \"GPU memory info:\\n\" + \n",
    "          f\"Physical  memory : {byte_gb_info(t)}\\n\" + \n",
    "          f\"Reserved  memory : {byte_gb_info(r)}\\n\" + \n",
    "          f\"Allocated memory : {byte_gb_info(a)}\\n\" + \n",
    "          f\"Free      memory : {byte_gb_info(f)}\")\n",
    "\n",
    "    \n",
    "def accelerator_compute_info(device_idx: int):\n",
    "    name = torch.cuda.get_device_properties(device_idx).name\n",
    "    count = torch.cuda.get_device_properties(device_idx).multi_processor_count\n",
    "    print(f\"Device_name      : {name} \\n\" +\n",
    "          f\"Multi_processor  : {count}\")    \n",
    "\n",
    "    \n",
    "def gpu_usage():        \n",
    "    num_of_gpus = torch.cuda.device_count();\n",
    "    # this shows only the gpu device, not the MIG\n",
    "    print(f\"num_of_gpus: {num_of_gpus}\")\n",
    "    # available_gpus = [torch.cuda.device(i) for i in range(torch.cuda.device_count())]\n",
    "    # available_gpus = [torch.cuda.get_device_properties(i).name for i in range(torch.cuda.device_count())]\n",
    "    # print(f\"device_mig_info: {available_gpus}\")\n",
    "    for device_idx in range(torch.cuda.device_count()):\n",
    "        print(\"-\"*20)\n",
    "        accelerator_compute_info(device_idx)                 \n",
    "        accelerator_mem_info(device_idx)\n",
    "        print(\"-\"*20)\n",
    "    # Why is there two cuda mem info ? \"avaialbe and total\" ?\n",
    "    # max_memory=[f'{int(torch.cuda.mem_get_info()[i]/1024**3)-2}GB' for i in range(len(torch.cuda.mem_get_info()))]\n",
    "    # print(f\"max_memory: {max_memory}\")\n",
    "\n",
    "    \n",
    "gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68f45ef-874d-4539-9564-81772f85a74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the model download cache directory\n",
    "# DATA_ROOT=\"/data\"\n",
    "# DATA_ROOT=\"/home/jovyan/llm-models\"\n",
    "# os.environ['XDG_CACHE_HOME']=f\"{DATA_ROOT}/core-kind/yinwang/models\"\n",
    "\n",
    "model_map = {\n",
    "        \"7B\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "        \"13B\" : \"meta-llama/Llama-2-13b-chat-hf\",\n",
    "        \"70B\" : \"meta-llama/Llama-2-70b-chat-hf\",\n",
    "        # \"70B\" : \"meta-llama/Llama-2-70b-hf\" \n",
    "}\n",
    "\n",
    "import transformers\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aeb893-f4f5-484a-b95b-28f7728c18f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the token\n",
    "\"\"\"\n",
    "token_file_path = f\"{DATA_ROOT}/core-kind/yinwang/.cache/huggingface/token\"\n",
    "file = open(token_file_path, \"r\")\n",
    "# file read add a new line to the token, remove it.\n",
    "token = file.read().replace('\\n', '')\n",
    "file.close()\n",
    "\n",
    "# print the raw string to see if there is new line in the token\n",
    "# print(r'{}'.format(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0b9ef8-b1be-4d77-8959-b5c4262721c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_type = \"13B\"\n",
    "model_type = \"7B\"\n",
    "model_name = model_map.get(model_type, \"7B\")\n",
    "\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b9a854-49ad-4c97-ba33-f7f7d6edb353",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name, \n",
    "    #token=token, #transformer==4.32.1\n",
    "    use_auth_token=token, #transformer==4.31.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18b436d-e07e-4c3b-a1f7-e73c602b7638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c825194-473c-4f05-a1e4-9feb6b2475e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# in Transformer 4.32.1 need to use \"token\" parameter\n",
    "# in Transformer 4.30.x need to use \"use_auth_token\" parameter\n",
    "# with torch.no_grad():\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    #token=token, #transformer==4.32.1\n",
    "    use_auth_token=token, #transformer==4.31.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0308f6-5431-4ed9-af26-b9d0be6c3d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056d0ca9-6fb6-4999-8ba4-979a3d16ad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the available GPU memory after loading the LLM\n",
    "gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267a6e3f-7456-4e36-af4d-7ca1ed807e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_gen(\n",
    "    generator: transformers.pipelines.text_generation.TextGenerationPipeline, \n",
    "    tokenizer: transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast\n",
    "):    \n",
    "    def local(input: str, print_mode: bool = True) -> list:\n",
    "        start = time.time()\n",
    "        sequences = generator(\n",
    "            input,\n",
    "            do_sample=True,\n",
    "            top_k=10,\n",
    "            num_return_sequences=1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            # max_length=200,\n",
    "            max_new_tokens=200,\n",
    "        )\n",
    "        # for seq in sequences:\n",
    "        #     print(f\"Result: \\n{seq['generated_text']}\")\n",
    "        \n",
    "        result = []\n",
    "        for seq in sequences:\n",
    "            result.append(f\"Result: \\n{seq['generated_text']}\")\n",
    "        \n",
    "        end = time.time()\n",
    "        duration = end - start\n",
    "        if print_mode == True:\n",
    "            for s in result:\n",
    "                print(s)\n",
    "\n",
    "            print(\"-\"*20)\n",
    "            print(f\"walltime: {duration} in secs.\")\n",
    "            gpu_usage() \n",
    "        return result\n",
    "            \n",
    "    \n",
    "    return local\n",
    "    \n",
    "chat = chat_gen(generator, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f775ca5a-1974-4837-8821-b556266cee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set DEBUG to false to remove all the llm answer outputs\n",
    "# DEBUG=True\n",
    "DEBUG=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897b8269-5855-4d49-8b2a-f028dcffb1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_answer(answer: list)-> None:\n",
    "    if DEBUG:\n",
    "        print(\"-\"*10)\n",
    "        print(answer[0])\n",
    "        print(\"-\"*10)\n",
    "        print(answer[0].split(\"\\n\")[-1])        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3825e756-89ce-4a3a-9592-cf00f2bcf10c",
   "metadata": {},
   "source": [
    "#### Free pytorch gpu memory\n",
    "* https://discuss.pytorch.org/t/how-to-delete-a-tensor-in-gpu-to-free-up-memory/48879/5\n",
    "* https://discuss.huggingface.co/t/clear-gpu-memory-of-transformers-pipeline/18310\n",
    "* https://saturncloud.io/blog/how-to-free-up-all-memory-pytorch-is-taking-from-gpu-memory/\n",
    "* https://discuss.pytorch.org/t/how-to-free-the-pytorch-transformers-model-from-gpu-memory/132968\n",
    "* https://stackoverflow.com/questions/70508960/how-to-free-gpu-memory-in-pytorch\n",
    "\n",
    "#### Huggingface pipelines\n",
    "* https://huggingface.co/docs/transformers/main_classes/pipelines\n",
    "* clean cuda torch gpu: https://stackoverflow.com/questions/55322434/how-to-clear-cuda-memory-in-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d64be04-c528-426b-91f1-47b71996d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def free_memory_gen(\n",
    "    generator: transformers.pipelines.text_generation.TextGenerationPipeline, \n",
    "    tokenizer: transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def local():\n",
    "        l_generator = generator\n",
    "        l_tokenizer = tokenizer\n",
    "        #l_generator.cpu()\n",
    "        #l_tokenizer.cpu()\n",
    "        # model.cpu()\n",
    "        \n",
    "        del l_tokenizer, l_generator\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        #for device_idx in range(torch.cuda.device_count()):\n",
    "        #    print(device_idx)\n",
    "        #    device = torch.device(f\"cuda:{device_idx}\")\n",
    "        #    device.reset()\n",
    "    return local    \n",
    "\n",
    "free_memory = free_memory_gen(generator, tokenizer)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfad65b-f23b-4e99-b724-57dd530b99bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain of thoughts prompting\n",
    "\n",
    "# testing prompt\n",
    "input='Q: Roger has 3 tennis balls. He buys 2 more cans of tennis balls. Each can has 4 tennis balls. How many tennis balls does he have now?\\nA: Roger started with 3 balls. 2 cans of 4 tennis balls each is 8 tennis balls. 3 + 8 = 11. The answer is 11.\\nQ: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\\n'\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e5c6f4-0456-4ec5-9711-c145c7f862ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = chat(input, False)\n",
    "#print_answer(answer)\n",
    "print(answer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d410207-f7de-4ebf-80cc-436217ee8206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf_text_loader import PDFHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc455c76-8203-4541-a82e-80444bf1835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loader = PDFHelper(data_folder = \"./data/medreports\", file_pattern=\"KK-SCIVIAS-*.pdf\")\n",
    "#context = loader.read_pdf(1)\n",
    "\n",
    "#input = f\"Context: Patient: Fried\\nFrage: Welcher name hat der Patient?\\nAntwort: Name ist Fried\\nContext: {context}\\nFrage: Welcher name hat die Patientin?\\nAntwort: die Patientin hat name \"\n",
    "#print(input)\n",
    "#chat(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1942d22b-8e04-4d37-9e08-fe3f25e5d418",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"core-kind/yinwang\"\n",
    "loader = PDFHelper(data_folder = f\"{DATA_ROOT}/{data_path}/data/medreports\", file_pattern=\"KK-SCIVIAS-*.txt\")\n",
    "context = loader.read_txt(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861587f9-f41e-4ce3-903b-ec50b17f4cce",
   "metadata": {},
   "source": [
    "#### zero shot prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5316fa-82d8-4f47-98fa-9506916a1eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#name\n",
    "input=f\"Can you tell me the name of the patient from the folowing doctor's letter?\\nLetter:\\n{context}\\nAnswer: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd6b804-67bd-4c54-a7c2-0e5ef14aa8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(input)\n",
    "# 6810"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780a0f12-7d99-4aba-9c8a-5fb1e28f456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=chat(input, print_mode=False)\n",
    "print_answer(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c299015-c5b7-425b-8a79-ba155491c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#age\n",
    "input=f\"Can you tell me the age of the patient from the following doctor's letter?\\nLetter:\\n{context}\\nAnswer: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcf966a-76c1-4e7d-8a6d-0b356b2b86b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=chat(input, print_mode=False)\n",
    "print_answer(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d472f-80db-4d73-ac73-f673bc5fe279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#diagnosis\n",
    "input=f\"Can you tell me the diagnosis of the patient from the following doctor's letter?\\nLetter:\\n{context}\\nAnswer: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d7927d-9cba-4cbf-a05c-4fcaf886c7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=chat(input, print_mode=False)\n",
    "print_answer(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbfa11f-0eb2-4dac-aa70-194cfe8e577d",
   "metadata": {},
   "source": [
    "#### Chain-of-thoughts prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc858b23-c973-4dbc-9b4c-24131f90eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name prompt\n",
    "input = f\"Context: Patient: Fried\\nQuestion: what is the name of the patient? \\nAnswer: Name of the patient is Fried\\nContext: {context}\\nQuestion: what is the name of the patient?\\nAnswer: the name of patient is\"\n",
    "#print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7881162a-6514-4f31-a64c-60718b2f6338",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=chat(input, print_mode=False)\n",
    "print_answer(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e61eea4-3731-4ba5-8c1b-e392cc6fe998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age prompt\n",
    "input = f\"Context:\\nPatient: Fried is a 34-year-old patient\\nQuestion:\\nhow old is the patient? \\nAnswer:\\nFried is a patient, 34 year-old, the answers is 34\\nContext:\\n{context}\\nQuestion:\\nhow old is the patient?\\nAnswer: \"\n",
    "# print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca31ec3d-1912-4a07-aab0-c84151783112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age prompt\n",
    "#len(input)\n",
    "# > 6913 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fbeb59-1fe4-4ab0-b004-05b2fe2d1444",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=chat(input, print_mode=False)\n",
    "print_answer(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a401151-af8b-46f4-8ef2-0177ae075f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnose prompt\n",
    "input=f\"Context:\\nPatient: Fried is a 34-year-old patient, Diagnoses: Influenza (J09.X2) \\nQuestion:\\nWhat diagnoses has the patient? \\nAnswer:\\nFried is a patient, 34 year-old, has diagnoses Influenza (J09.X2). The answers is Influenza (J09.X2)\\nContext:\\n{context}\\nQuestion:\\nWhat diagnoses has the patient?\\nAnswer: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd94444-a458-40dd-b95d-2be26f9ad5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=chat(input, print_mode=False)\n",
    "print_answer(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374b6e3c-3d58-4cf6-b834-1d066519e967",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024d74a3-4ef3-4379-9075-a3944812244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "free_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4aca2a-e1cc-4769-bdd8-268906d978d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d4464c-2597-4eed-b3b1-16e67d966fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
