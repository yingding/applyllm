{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34bde0f4-67cd-4a5a-af8c-abf0f89a15f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0003cb5d-2144-4d17-9d9c-ca060d3acbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install --upgrade --user kfp==1.8.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f01c1e77-1584-4cc6-80ee-95ea349396f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "from functools import partial\n",
    "from kfp.dsl import (\n",
    "    pipeline,\n",
    "    ContainerOp,\n",
    "    PipelineVolume\n",
    ")\n",
    "from kfp.components import (\n",
    "    InputPath,\n",
    "    OutputPath,\n",
    "    create_component_from_func\n",
    ")\n",
    "\n",
    "EXPERIMENT_NAME = 'llm' # Name of the experiment in the KF webapp UI\n",
    "EXPERIMENT_DESC = 'llm med report pipeline experiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c7bb3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Settings():\n",
    "    llm_base_image: str = 'pytorch/pytorch:2.2.0-cuda11.8-cudnn8-devel'\n",
    "    applyllm_version: str = '0.0.2'\n",
    "    pypdf_version: str = '3.15.5'\n",
    "\n",
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7763edd5-3c2e-44c5-afb1-3983a46d0772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "@partial(\n",
    "    create_component_from_func,\n",
    "    output_component_file=f\"custom_registry_component.yaml\",\n",
    "    base_image=settings.llm_base_image, \n",
    "    packages_to_install=[\n",
    "        f\"applyllm=={settings.applyllm_version}\",\n",
    "        f\"pypdf=={settings.pypdf_version}\",\n",
    "    ], # adding additional libs\n",
    "    # pip_index_urls=[\"https://gitlab.lrz.de/api/v4/projects/150553/packages/pypi/simple\"]\n",
    "    # define my private pypi package registry v2 component decorator\n",
    ")\n",
    "def llm_op():\n",
    "    import applyllm as apl\n",
    "    print(f\"applyllm version: {apl.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d9dc48c-75de-4812-8177-a27b5a414067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_res_limits(task: ContainerOp, mem_req=\"200Mi\", cpu_req=\"2000m\", mem_lim=\"4000Mi\", cpu_lim='4000m', gpu_req=None, gpu_lim=None, gpu_type:str=\"20gb\"):\n",
    "    \"\"\"\n",
    "    this function helps to set the resource limit for container operators\n",
    "    op.set_memory_limit('1000Mi') = 1GB\n",
    "    op.set_cpu_limit('1000m') = 1 cpu core\n",
    "    \"\"\"\n",
    "    if gpu_type == \"20gb\":\n",
    "        gpu_resource = \"nvidia.com/mig-2g.20gb\"\n",
    "        # gpu_resource = \"nvidia.com/mig-1g.20gb\"\n",
    "    else:\n",
    "        gpu_resource = \"nvidia.com/mig-1g.10gb\"\n",
    "        \n",
    "    # gpu_resource = \"nvidia.com/mig-2g.20gb\"\n",
    "    new_op = task.set_memory_request(mem_req)\\\n",
    "        .set_memory_limit(mem_lim)\\\n",
    "        .set_cpu_request(cpu_req)\\\n",
    "        .set_cpu_limit(cpu_lim)\n",
    "    if (gpu_req is not None) and (gpu_lim is not None):\n",
    "        new_op.add_resource_request(gpu_resource, gpu_req)\n",
    "        new_op.add_resource_limit(gpu_resource, gpu_lim)\n",
    "    return new_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a2af7a2-4166-4ac5-84fb-93f24b49bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(\n",
    "    name = EXPERIMENT_NAME,\n",
    "    description = EXPERIMENT_DESC\n",
    ")\n",
    "def llm_pipeline():\n",
    "    '''local variable'''\n",
    "    no_artifact_cache = \"P0D\"\n",
    "    artifact_cache_today = \"P1D\"\n",
    "    # cache_setting = artifact_cache_today\n",
    "    cache_setting = no_artifact_cache\n",
    "\n",
    "    '''Pipeline Volume'''\n",
    "    shared_volume = PipelineVolume(\"llm-models\")\n",
    "    \n",
    "    '''pipeline'''   \n",
    "    llm_task = llm_op()\n",
    "    # 200 MB ram and 1 cpu\n",
    "    llm_task = set_res_limits(task=llm_task, mem_req=\"20Gi\", mem_lim=\"40Gi\",\n",
    "                            cpu_req=\"2000m\", cpu_lim=\"10000m\", \n",
    "                            gpu_req=1, gpu_lim=1, gpu_type=\"20gb\")\n",
    "    # set the download caching to be 1day, disable caching with P0D\n",
    "    # download_task.execution_options.caching_strategy.max_cache_staleness = artifact_cache_today\n",
    "    llm_task.execution_options.caching_strategy.max_cache_staleness = cache_setting\n",
    "    llm_task.set_display_name(\"llm op\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "739fe18f-2384-4bbb-a9bb-7e284b028903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pipeline_path_dir=\"./compiled\"\n",
    "if not os.path.exists(pipeline_path_dir):\n",
    "    os.makedirs(pipeline_path_dir)\n",
    "\n",
    "PIPE_LINE_FILE_NAME=f\"llm_rag_kfp_pipeline\"\n",
    "kfp.compiler.Compiler().compile(llm_pipeline, f\"{pipeline_path_dir}/{PIPE_LINE_FILE_NAME}.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "934304c5-326f-4d67-85d5-9920d1683590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pytz import timezone as ptimezone\n",
    "\n",
    "def get_local_time_str(target_tz_str: str = \"Europe/Berlin\", format_str: str = \"%Y-%m-%d %H-%M-%S\") -> str:\n",
    "    \"\"\"\n",
    "    this method is created since the local timezone is miss configured on the server\n",
    "    @param: target timezone str default \"Europe/Berlin\"\n",
    "    @param: \"%Y-%m-%d %H-%M-%S\" returns 2022-07-07 12-08-45\n",
    "    \"\"\"\n",
    "    target_tz = ptimezone(target_tz_str) # create timezone, in python3.9 use standard lib ZoneInfo\n",
    "    # utc_dt = datetime.now(datetime.timezone.utc)\n",
    "    target_dt = datetime.now(target_tz)\n",
    "    return datetime.strftime(target_dt, format_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2118ac78-8984-475f-9c0b-d4c530e60ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kubernetes import client as k8s_client\n",
    "pipeline_config = dsl.PipelineConf()\n",
    "\n",
    "# pipeline_config.set_image_pull_secrets([k8s_client.V1ObjectReference(name=K8_GIT_SECRET_NAME, namespace=NAME_SPACE)])\n",
    "# pipeline_config.set_image_pull_policy(\"Always\")\n",
    "pipeline_config.set_image_pull_policy(\"IfNotPresent\")\n",
    "\n",
    "pipeline_args = {\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66a646a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NAME = f\"{PIPE_LINE_FILE_NAME} {get_local_time_str()}\"\n",
    "\n",
    "client = kfp.Client()\n",
    "NAMESPACE = client.get_user_namespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "830b1ac0-ae9f-47e5-8896-1f3c1d7672ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/f5eabfa0-38e1-4828-a8ec-09d2adc66e22\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/9405bb18-df37-408f-96f3-19fb50d0423b\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=9405bb18-df37-408f-96f3-19fb50d0423b)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = client.create_run_from_pipeline_func(\n",
    "    pipeline_func=llm_pipeline,\n",
    "    arguments = pipeline_args, #{}\n",
    "    run_name = RUN_NAME,\n",
    "    pipeline_conf=pipeline_config,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    namespace=NAMESPACE,\n",
    ")\n",
    "\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f38559-6dd4-40ad-91f6-85f3df4387ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4192ac26-d24f-41ca-b726-b9122f53fb6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm3.10",
   "language": "python",
   "name": "llm3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
