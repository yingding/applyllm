{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34bde0f4-67cd-4a5a-af8c-abf0f89a15f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0003cb5d-2144-4d17-9d9c-ca060d3acbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install --upgrade --user kfp==1.8.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f01c1e77-1584-4cc6-80ee-95ea349396f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kubeflow-kindfor\n"
     ]
    }
   ],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "from functools import partial\n",
    "from kfp.dsl import (\n",
    "    pipeline,\n",
    "    ContainerOp\n",
    ")\n",
    "from kfp.components import (\n",
    "    InputPath,\n",
    "    OutputPath,\n",
    "    create_component_from_func\n",
    ")\n",
    "client = kfp.Client()\n",
    "NAMESPACE = client.get_user_namespace()\n",
    "EXPERIMENT_NAME = 'llm' # Name of the experiment in the KF webapp UI\n",
    "EXPERIMENT_DESC = 'llm experiment'\n",
    "\n",
    "print(NAMESPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2198f273-03af-4bfc-a298-ccfbab779cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Settings():\n",
    "    llm_base_image: str = 'pytorch/pytorch:2.2.0-cuda11.8-cudnn8-devel'\n",
    "    # s3_base_image: str = 'python:3.10.13-slim-bullseye'\n",
    "    # use a runtime pytorch image to speed up the pip install process, since the applyllm has too many dependencies\n",
    "    # TODO: to seperate applyllm-io an applyllm package\n",
    "    s3_base_image: str = 'pytorch/pytorch:2.2.0-cuda11.8-cudnn8-runtime'\n",
    "    applyllm_version: str = '0.0.3'\n",
    "    pypdf_version: str = '3.15.5'\n",
    "    accelerate_version: str = '0.26.1'\n",
    "    unstructured_version: str = '0.11.0'\n",
    "    sentence_transformers_version: str = '2.2.2'\n",
    "    docarray_version: str = '0.39.1'\n",
    "    pydantic_version: str = '1.10.13'\n",
    "    boto3_version: str = '1.34.14'\n",
    "    pandas_version: str = '2.2.1'\n",
    "    tabula_py_version: str = '2.9.0'\n",
    "\n",
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf2c6366-baf0-49e6-a962-dbc8555e7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PIPELINE_PATH_DIR = \"./compiled\"\n",
    "if not os.path.exists(PIPELINE_PATH_DIR):\n",
    "    os.makedirs(PIPELINE_PATH_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad4c3ad-805b-444a-8417-46795b4c10db",
   "metadata": {},
   "source": [
    "## Check Tabula in s3 pdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7763edd5-3c2e-44c5-afb1-3983a46d0772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "@partial(\n",
    "    create_component_from_func,\n",
    "    output_component_file=f\"{PIPELINE_PATH_DIR}/s3_pdf_tabula_check_component.yaml\",\n",
    "    base_image=settings.s3_base_image, \n",
    "    packages_to_install=[\n",
    "        f\"applyllm=={settings.applyllm_version}\",\n",
    "        f\"boto3=={settings.boto3_version}\",\n",
    "        f\"pandas=={settings.pandas_version}\",\n",
    "        f\"tabula-py=={settings.tabula_py_version}\"\n",
    "    ],\n",
    ")\n",
    "def file_comp(\n",
    "        bucket_name: str,\n",
    "        verify_host: bool,\n",
    "        file_prefix: str,\n",
    "        limit_count: int,\n",
    "        output_path: OutputPath(\"CSV\"),\n",
    "    ):\n",
    "    import boto3, os\n",
    "    import pandas as pd\n",
    "    import tabula\n",
    "    from io import BytesIO\n",
    "    # from pypdf import PdfReader\n",
    "    from applyllm.io import (\n",
    "        S3AccessConf,\n",
    "        S3BucketHelper,\n",
    "    )\n",
    "    from applyllm.utils import time_func \n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", message=\"ICC profile\")\n",
    "    warnings.filterwarnings(\"ignore\", message=\"org.apache.pdfbox\")\n",
    "\n",
    "    s3_conf = S3AccessConf(\n",
    "        access_key_id = os.environ.get('AWS_ACCESS_KEY_ID'),\n",
    "        secret_access_key = os.environ.get('AWS_SECRET_ACCESS_KEY'),\n",
    "        endpoint = os.environ.get('S3_ENDPOINT'),\n",
    "        bucket_name = bucket_name,\n",
    "        verify_host = verify_host,\n",
    "    )\n",
    "    s3_pdf_reports_helper = S3BucketHelper(conf=s3_conf, file_prefix=file_prefix)\n",
    "\n",
    "    session = boto3.session.Session(\n",
    "        aws_access_key_id = os.environ.get('AWS_ACCESS_KEY_ID'),\n",
    "        aws_secret_access_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "    )\n",
    "    s3 = session.resource('s3', \n",
    "                          endpoint_url = os.environ.get('S3_ENDPOINT'), \n",
    "                          verify=verify_host)\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "    def get_s3_pdf_bytesio(s3, bucket_name, key: str):\n",
    "        obj = s3.Object(bucket_name, key)\n",
    "        return obj.get()['Body'].read()\n",
    "    \n",
    "    def extract_tables(pdf_bytesio, page_numbers='all', stream=True):\n",
    "        \"\"\"\n",
    "        Extract tables from a PDF and organize the data into a list of combined dictionaries.\n",
    "        \n",
    "        Parameters:\n",
    "        - pdf_path: Path to the PDF file.\n",
    "        - page_numbers: Pages to extract tables from ('all' for all pages).\n",
    "        \n",
    "        Returns:\n",
    "        - A list of dictionaries, each representing combined data from the same column across all tables.\n",
    "        \"\"\"\n",
    "        # Extract all tables from the specified pages of the PDF\n",
    "        # tables is a list of pandas DataFrame\n",
    "        df_list = tabula.read_pdf(pdf_bytesio, pages=page_numbers, multiple_tables=True, pandas_options={'header': None}, stream=stream)\n",
    "        return df_list\n",
    "\n",
    "    def contains_table(pdf_bytesio):\n",
    "        df_list = extract_tables(pdf_bytesio, page_numbers='all')\n",
    "        return df_list is not None and len(df_list) > 0\n",
    "    \n",
    "    contains_table_map = map(\n",
    "        lambda x: {\n",
    "            \"key\": str(x),\n",
    "            \"contains_table\": contains_table(BytesIO(get_s3_pdf_bytesio(s3, bucket_name, x)))\n",
    "        }, s3_pdf_reports_helper.get_object_keys(limit_count=limit_count))\n",
    "\n",
    "    @time_func\n",
    "    def get_results():\n",
    "        return list(contains_table_map)\n",
    "    \n",
    "    contains_table_dict_list = get_results()\n",
    "\n",
    "    key_list = []\n",
    "    has_table_list = []\n",
    "    for dict in contains_table_dict_list:\n",
    "        key_list.append(dict['key'])\n",
    "        has_table_list.append(dict['contains_table'])\n",
    "\n",
    "    data = {'key': key_list,'contains_table': has_table_list}\n",
    "    result_df = pd.DataFrame.from_dict(data)\n",
    "    \n",
    "    with open(output_path, \"w+\", encoding=\"utf-8\") as f:\n",
    "        result_df.to_csv(f, index=False, header=True, encoding=\"utf-8\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d9dc48c-75de-4812-8177-a27b5a414067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pod_resource_transformer(task: ContainerOp, mem_req=\"200Mi\", cpu_req=\"2000m\", mem_lim=\"4000Mi\", cpu_lim='4000m'):\n",
    "    \"\"\"\n",
    "    this function helps to set the resource limit for container operators\n",
    "    op.set_memory_limit('1000Mi') = 1GB\n",
    "    op.set_cpu_limit('1000m') = 1 cpu core\n",
    "    \"\"\"\n",
    "    return task.set_memory_request(mem_req)\\\n",
    "            .set_memory_limit(mem_lim)\\\n",
    "            .set_cpu_request(cpu_req)\\\n",
    "            .set_cpu_limit(cpu_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a2af7a2-4166-4ac5-84fb-93f24b49bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(\n",
    "    name = EXPERIMENT_NAME,\n",
    "    description = EXPERIMENT_DESC\n",
    ")\n",
    "def custom_pipeline(\n",
    "        bucket_name: str = \"scivias-medreports\",\n",
    "        verify_host: bool = True,\n",
    "        file_prefix: str = \"KK-SCIVIAS\",\n",
    "        limit_count: int = 3,\n",
    "        s3_secrets: str=\"add-scivias-medreport-secret\",\n",
    "    ):\n",
    "    '''local variable'''\n",
    "    no_artifact_cache = \"P0D\"\n",
    "    artifact_cache_today = \"P1D\"\n",
    "    # cache_setting = artifact_cache_today\n",
    "    cache_setting = no_artifact_cache\n",
    "    \n",
    "    '''pipeline'''   \n",
    "    check_task = file_comp(\n",
    "        bucket_name=bucket_name,\n",
    "        verify_host=verify_host,\n",
    "        file_prefix=file_prefix,\n",
    "        limit_count=limit_count,\n",
    "    )\n",
    "    # 200 MB ram and 1 cpu\n",
    "    check_task = pod_resource_transformer(check_task, mem_req=\"1Gi\", mem_lim=\"5Gi\", cpu_req=\"2000m\", cpu_lim=\"10000m\")\n",
    "    # set the download caching to be 1day, disable caching with P0D\n",
    "    # download_task.execution_options.caching_strategy.max_cache_staleness = artifact_cache_today\n",
    "    check_task.execution_options.caching_strategy.max_cache_staleness = cache_setting\n",
    "    check_task.set_display_name(\"check pdf tabula\")\n",
    "    check_task.add_pod_label(s3_secrets, \"true\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "739fe18f-2384-4bbb-a9bb-7e284b028903",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPE_LINE_FILE_NAME=f\"med_report_check_tabula_pipeline\"\n",
    "kfp.compiler.Compiler().compile(custom_pipeline, f\"{PIPE_LINE_FILE_NAME}.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "934304c5-326f-4d67-85d5-9920d1683590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pytz import timezone as ptimezone\n",
    "\n",
    "def get_local_time_str(target_tz_str: str = \"Europe/Berlin\", format_str: str = \"%Y-%m-%d %H-%M-%S\") -> str:\n",
    "    \"\"\"\n",
    "    this method is created since the local timezone is miss configured on the server\n",
    "    @param: target timezone str default \"Europe/Berlin\"\n",
    "    @param: \"%Y-%m-%d %H-%M-%S\" returns 2022-07-07 12-08-45\n",
    "    \"\"\"\n",
    "    target_tz = ptimezone(target_tz_str) # create timezone, in python3.9 use standard lib ZoneInfo\n",
    "    # utc_dt = datetime.now(datetime.timezone.utc)\n",
    "    target_dt = datetime.now(target_tz)\n",
    "    return datetime.strftime(target_dt, format_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2118ac78-8984-475f-9c0b-d4c530e60ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kubernetes import client as k8s_client\n",
    "pipeline_config = dsl.PipelineConf()\n",
    "\n",
    "# pipeline_config.set_image_pull_secrets([k8s_client.V1ObjectReference(name=K8_GIT_SECRET_NAME, namespace=NAME_SPACE)])\n",
    "# pipeline_config.set_image_pull_policy(\"Always\")\n",
    "pipeline_config.set_image_pull_policy(\"IfNotPresent\")\n",
    "\n",
    "pipeline_args = {\n",
    "    \"bucket_name\": \"scivias-medreports\",\n",
    "    \"verify_host\": True,\n",
    "    \"file_prefix\": \"KK-SCIVIAS\",\n",
    "    \"limit_count\": 3,\n",
    "    \"s3_secrets\": \"add-scivias-medreport-secret\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "830b1ac0-ae9f-47e5-8896-1f3c1d7672ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/f5eabfa0-38e1-4828-a8ec-09d2adc66e22\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/d7bca3b0-2a6e-4b60-95af-5ce6c6452d6e\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=d7bca3b0-2a6e-4b60-95af-5ce6c6452d6e)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RUN_NAME = f\"medreport check tabula pipeline {get_local_time_str()}\"\n",
    "\n",
    "# client = kfp.Client()\n",
    "run = client.create_run_from_pipeline_func(\n",
    "    pipeline_func=custom_pipeline,\n",
    "    arguments = pipeline_args, #{}\n",
    "    run_name = RUN_NAME,\n",
    "    pipeline_conf=pipeline_config,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    namespace=NAMESPACE,\n",
    ")\n",
    "\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f38559-6dd4-40ad-91f6-85f3df4387ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4192ac26-d24f-41ca-b726-b9122f53fb6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
